import java.net.URI

import org.apache.hadoop.fs.{FileSystem, Path}

val fs = FileSystem.get(new URI("hdfs://localhost:9000/"), spark.sparkContext.hadoopConfiguration)
println(spark.sparkContext.hadoopConfiguration)
val fsStatus = fs.listStatus(new Path("hdfs://localhost:9000/"))
fsStatus.foreach(x=> println(x.getPath))

val outputPath = new Path("/user/spark/trends")
println(fs.exists(outputPath), outputPath)
if (fs.exists(outputPath))
  fs.delete(outputPath, true)

println("Writing...")
trendsDF.rdd.saveAsTextFile("hdfs://localhost:9000/user/spark/trends")
println("Finished writing.")

println("Reading...")
val dfFromFile = spark.read.text("hdfs://localhost:9000/user/spark/trends")
println("Finished Reading.")

println("dfFromFile output")
dfFromFile.show(false)